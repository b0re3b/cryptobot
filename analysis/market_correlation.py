from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional, Union
import numpy as np
import pandas as pd
from DMP.market_data_processor import MarketDataProcessor
from data.db import DatabaseManager
from utils.config import *
from utils.logger import CryptoLogger


class MarketCorrelation:

    def __init__(self):
        self.logger = CryptoLogger('correlation')
        self.db_manager = DatabaseManager()
        self.data_processor = MarketDataProcessor()

        self.logger.info("–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ —Ä–∏–Ω–∫–æ–≤–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó")

        self.config = DEFAULT_CONFIG.copy()


    def _update_config_recursive(self, target_dict: Dict, source_dict: Dict) -> None:
        """
           –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–Ω–æ–≤–ª—é—î —Å–ª–æ–≤–Ω–∏–∫ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –Ω–æ–≤–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ –∑ —ñ–Ω—à–æ–≥–æ —Å–ª–æ–≤–Ω–∏–∫–∞.

           –Ø–∫—â–æ –∫–ª—é—á –ø—Ä–∏—Å—É—Ç–Ω—ñ–π —É –æ–±–æ—Ö —Å–ª–æ–≤–Ω–∏–∫–∞—Ö —ñ –æ–±–∏–¥–≤–∞ –∑–Ω–∞—á–µ–Ω–Ω—è —î —Å–ª–æ–≤–Ω–∏–∫–∞–º–∏,
           –≤—ñ–¥–±—É–≤–∞—î—Ç—å—Å—è —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è. –Ü–Ω–∞–∫—à–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ source_dict –ø–µ—Ä–µ–ø–∏—Å—É—î
           –∑–Ω–∞—á–µ–Ω–Ω—è –≤ target_dict.

           Parameters:
               target_dict (Dict): –¶—ñ–ª—å–æ–≤–∏–π —Å–ª–æ–≤–Ω–∏–∫, —è–∫–∏–π –±—É–¥–µ –æ–Ω–æ–≤–ª–µ–Ω–æ.
               source_dict (Dict): –°–ª–æ–≤–Ω–∏–∫ —ñ–∑ –Ω–æ–≤–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏.

           Returns:
               None
           """
        for key, value in source_dict.items():
            if key in target_dict and isinstance(target_dict[key], dict) and isinstance(value, dict):
                self._update_config_recursive(target_dict[key], value)
            else:
                self.logger.debug(f"–û–Ω–æ–≤–ª–µ–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó: {key} = {value}")
                target_dict[key] = value

    def calculate_price_correlation(self, symbols: List[str],
                                    timeframe: str = None,
                                    start_time: Optional[datetime] = None,
                                    end_time: Optional[datetime] = None,
                                    method: str = None) -> pd.DataFrame:
        """
           –û–±—á–∏—Å–ª—é—î –∫–æ—Ä–µ–ª—è—Ü—ñ—é —Ü—ñ–Ω –∑–∞–∫—Ä–∏—Ç—Ç—è –¥–ª—è –∑–∞–¥–∞–Ω–∏—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤.

           –î–∞–Ω—ñ –æ—Ç—Ä–∏–º—É—é—Ç—å—Å—è –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö –∑–∞ –≤–∫–∞–∑–∞–Ω–∏–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º —ñ –ø–µ—Ä—ñ–æ–¥–æ–º —á–∞—Å—É.
           –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö.

           Parameters:
               symbols (List[str]): –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç.
               timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–∏—Ö. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è.
               start_time (datetime, optional): –ü–æ—á–∞—Ç–∫–æ–≤–∞ –¥–∞—Ç–∞. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è lookback –ø–µ—Ä—ñ–æ–¥.
               end_time (datetime, optional): –ö—ñ–Ω—Ü–µ–≤–∞ –¥–∞—Ç–∞. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Ç–æ—á–Ω–∏–π —á–∞—Å.
               method (str, optional): –ú–µ—Ç–æ–¥ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 'pearson', 'kendall', 'spearman').

           Returns:
               pd.DataFrame: –ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ü—ñ–Ω.
           """
        # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω—ñ
        timeframe = self.config['default_timeframe']
        method = self.config['default_correlation_method']

        self.logger.info(f"–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ü—ñ–Ω –¥–ª—è {len(symbols)} —Å–∏–º–≤–æ–ª—ñ–≤ –∑ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º {timeframe}")

        # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∫—ñ–Ω—Ü–µ–≤–æ–≥–æ —á–∞—Å—É —è–∫ –ø–æ—Ç–æ—á–Ω–∏–π, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ
        end_time = end_time or datetime.now()

        # –Ø–∫—â–æ –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —á–∞—Å –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
        if start_time is None:
            lookback_days = self.config['default_lookback_days']
            start_time = end_time - timedelta(days=lookback_days)
            self.logger.debug(f"–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–µ—Ä—ñ–æ–¥—É –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: {lookback_days} –¥–Ω—ñ–≤")

        try:
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ü—ñ–Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö –∑–∞–º—ñ—Å—Ç—å Binance API
            price_data = {}
            for symbol in symbols:
                self.logger.debug(f"–û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è {symbol}")
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ db_manager.get_klines –∑–∞–º—ñ—Å—Ç—å binance_client.get_historical_prices
                price_data[symbol] = self.db_manager.get_klines(
                    symbol=symbol,
                    timeframe=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É –∑ —Ü—ñ–Ω–∞–º–∏ –∑–∞–∫—Ä–∏—Ç—Ç—è –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤
            df = pd.DataFrame()
            for symbol, data in price_data.items():
                data['open_time'] = pd.to_datetime(data['open_time'], unit='s')  # –∞–±–æ unit='ms' ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä —Ñ–æ—Ä–º–∞—Ç
                data.set_index('open_time', inplace=True)
                df[symbol] = data['close']

            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ –¥–∞–Ω—ñ
            if df.isnull().values.any():
                missing_count = df.isnull().sum().sum()
                self.logger.warning(f"–í–∏—è–≤–ª–µ–Ω–æ {missing_count} –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö –∑–Ω–∞—á–µ–Ω—å. –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –º–µ—Ç–æ–¥–æ–º forward fill")
                df = df.fillna(method='ffill')

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–∞—Ç—Ä–∏—Ü—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
            correlation_matrix = df.corr(method=method)

            self.logger.info(f"–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ü—ñ–Ω —É—Å–ø—ñ—à–Ω–æ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–∞ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –º–µ—Ç–æ–¥—É {method}")

            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É –±–∞–∑—É –¥–∞–Ω–∏—Ö
            self.save_correlation_to_db(
                correlation_matrix=correlation_matrix,
                correlation_type='price',
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                method=method
            )

            return correlation_matrix

        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ü—ñ–Ω: {str(e)}")
            raise

    def calculate_volume_correlation(self, symbols: List[str],
                                     timeframe: str = None,
                                     start_time: Optional[datetime] = None,
                                     end_time: Optional[datetime] = None,
                                     method: str = None) -> pd.DataFrame:
        """
            –û–±—á–∏—Å–ª—é—î –∫–æ—Ä–µ–ª—è—Ü—ñ—é –æ–±'—î–º—ñ–≤ —Ç–æ—Ä–≥—ñ–≤–ª—ñ –¥–ª—è –∑–∞–¥–∞–Ω–∏—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤.

            –î–∞–Ω—ñ –ø—Ä–æ –æ–±'—î–º–∏ –æ—Ç—Ä–∏–º—É—é—Ç—å—Å—è –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö. –ü—Ä–∏ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ –æ—á–∏—â–∞—é—Ç—å—Å—è –≤—ñ–¥ –≤–∏–∫–∏–¥—ñ–≤.
            –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö.

            Parameters:
                symbols (List[str]): –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç.
                timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–∏—Ö. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è.
                start_time (datetime, optional): –ü–æ—á–∞—Ç–∫–æ–≤–∞ –¥–∞—Ç–∞. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è lookback –ø–µ—Ä—ñ–æ–¥.
                end_time (datetime, optional): –ö—ñ–Ω—Ü–µ–≤–∞ –¥–∞—Ç–∞. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Ç–æ—á–Ω–∏–π —á–∞—Å.
                method (str, optional): –ú–µ—Ç–æ–¥ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 'pearson', 'kendall', 'spearman').

            Returns:
                pd.DataFrame: –ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–±'—î–º—ñ–≤.
            """
        # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω—ñ
        timeframe = timeframe or self.config['default_timeframe']
        method = method or self.config['default_correlation_method']

        self.logger.info(f"–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–±'—î–º—ñ–≤ —Ç–æ—Ä–≥—ñ–≤–ª—ñ –¥–ª—è {len(symbols)} —Å–∏–º–≤–æ–ª—ñ–≤ –∑ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º {timeframe}")

        # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∫—ñ–Ω—Ü–µ–≤–æ–≥–æ —á–∞—Å—É —è–∫ –ø–æ—Ç–æ—á–Ω–∏–π, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ
        end_time = end_time or datetime.now()

        # –Ø–∫—â–æ –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —á–∞—Å –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
        if start_time is None:
            lookback_days = self.config['default_lookback_days']
            start_time = end_time - timedelta(days=lookback_days)
            self.logger.debug(f"–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–µ—Ä—ñ–æ–¥—É –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: {lookback_days} –¥–Ω—ñ–≤")

        try:
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø—Ä–æ –æ–±'—î–º–∏ —Ç–æ—Ä–≥—ñ–≤–ª—ñ –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
            volume_data = {}
            for symbol in symbols:
                self.logger.debug(f"–û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø—Ä–æ –æ–±'—î–º–∏ –¥–ª—è {symbol}")
                volume_data[symbol] = self.db_manager.get_klines(
                    symbol=symbol,
                    timeframe=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É –∑ –æ–±'—î–º–∞–º–∏ —Ç–æ—Ä–≥—ñ–≤–ª—ñ –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤
            df = pd.DataFrame()
            for symbol, data in volume_data.items():
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –¥–æ float –≤—ñ–¥—Ä–∞–∑—É –ø—ñ–¥ —á–∞—Å —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É
                df[symbol] = data['volume'].astype(float)

            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
            if df.isnull().values.any():
                missing_count = df.isnull().sum().sum()
                self.logger.warning(f"–í–∏—è–≤–ª–µ–Ω–æ {missing_count} –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö –∑–Ω–∞—á–µ–Ω—å –æ–±'—î–º—É. –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –º–µ—Ç–æ–¥–æ–º forward fill")
                df = df.fillna(method='ffill')

            # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö –¥–ª—è —É—Å—É–Ω–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤
            for column in df.columns:
                mean_val = df[column].mean()
                std_val = df[column].std()
                upper_limit = mean_val + 3 * std_val

                # –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–Ω–∏—Ö –≤–∏–∫–∏–¥—ñ–≤ —Å–µ—Ä–µ–¥–Ω—ñ–º –∑–Ω–∞—á–µ–Ω–Ω—è–º
                outliers_mask = df[column] > upper_limit
                if outliers_mask.any():
                    outlier_count = outliers_mask.sum()
                    self.logger.warning(
                        f"–í–∏—è–≤–ª–µ–Ω–æ {outlier_count} –≤–∏–∫–∏–¥—ñ–≤ –æ–±'—î–º—É –¥–ª—è {column}. –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ –∑–∞ –º–µ–¥—ñ–∞–Ω–æ—é")
                    df.loc[outliers_mask, column] = df[column].median()

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–∞—Ç—Ä–∏—Ü—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
            correlation_matrix = df.corr(method=method)

            self.logger.info(f"–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–±'—î–º—ñ–≤ —Ç–æ—Ä–≥—ñ–≤–ª—ñ —É—Å–ø—ñ—à–Ω–æ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–∞ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –º–µ—Ç–æ–¥—É {method}")

            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É –±–∞–∑—É –¥–∞–Ω–∏—Ö
            self.save_correlation_to_db(
                correlation_matrix=correlation_matrix,
                correlation_type='volume',
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                method=method
            )

            return correlation_matrix

        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–±'—î–º—ñ–≤ —Ç–æ—Ä–≥—ñ–≤–ª—ñ: {str(e)}")
            raise

    def calculate_returns_correlation(self, symbols: List[str],
                                      timeframe: str = None,
                                      start_time: Optional[datetime] = None,
                                      end_time: Optional[datetime] = None,
                                      period: int = 1,
                                      method: str = None) -> pd.DataFrame:
        """
           –û–±—á–∏—Å–ª—é—î –º–∞—Ç—Ä–∏—Ü—é –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ (–≤—ñ–¥—Å–æ—Ç–∫–æ–≤–∏—Ö –∑–º—ñ–Ω) –¥–ª—è –∑–∞–¥–∞–Ω–∏—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤.

           –î–∞–Ω—ñ –±–µ—Ä—É—Ç—å—Å—è –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö, –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—é—Ç—å—Å—è –Ω–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ –∑ –≤–∫–∞–∑–∞–Ω–∏–º –ø–µ—Ä—ñ–æ–¥–æ–º —ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è
           –¥–ª—è –ø–æ–±—É–¥–æ–≤–∏ –º–∞—Ç—Ä–∏—Ü—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó.

           Args:
               symbols (List[str]): –°–ø–∏—Å–æ–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ["BTC", "ETH"]).
               timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–∏—Ö (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1d"). –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
               start_time (datetime, optional): –ü–æ—á–∞—Ç–∫–æ–≤–∞ –¥–∞—Ç–∞ –ø–µ—Ä—ñ–æ–¥—É. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–Ω—è lookback –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
               end_time (datetime, optional): –ö—ñ–Ω—Ü–µ–≤–∞ –¥–∞—Ç–∞ –ø–µ—Ä—ñ–æ–¥—É. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –±–µ—Ä–µ—Ç—å—Å—è –ø–æ—Ç–æ—á–Ω–∞ –¥–∞—Ç–∞.
               period (int, optional): –ü–µ—Ä—ñ–æ–¥ –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –≤—ñ–¥—Å–æ—Ç–∫–æ–≤–∏—Ö –∑–º—ñ–Ω (–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ). –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º 1.
               method (str, optional): –ú–µ—Ç–æ–¥ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó ('pearson', 'kendall', 'spearman').

           Returns:
               pd.DataFrame: –ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ –º—ñ–∂ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º–∏.
           """
        # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω—ñ
        timeframe = timeframe or self.config['default_timeframe']
        method = method or self.config['default_correlation_method']

        self.logger.info(
            f"–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ –¥–ª—è {len(symbols)} —Å–∏–º–≤–æ–ª—ñ–≤ –∑ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º {timeframe} —Ç–∞ –ø–µ—Ä—ñ–æ–¥–æ–º {period}")

        # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∫—ñ–Ω—Ü–µ–≤–æ–≥–æ —á–∞—Å—É —è–∫ –ø–æ—Ç–æ—á–Ω–∏–π, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ
        end_time = end_time or datetime.now()

        # –Ø–∫—â–æ –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —á–∞—Å –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
        if start_time is None:
            lookback_days = self.config['default_lookback_days']
            start_time = end_time - timedelta(days=lookback_days)
            self.logger.debug(f"–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–µ—Ä—ñ–æ–¥—É –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: {lookback_days} –¥–Ω—ñ–≤")

        try:
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ü—ñ–Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
            price_data = {}
            for symbol in symbols:
                self.logger.debug(f"–û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è {symbol}")
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ db_manager.get_klines –∑–∞–º—ñ—Å—Ç—å binance_client.get_historical_prices
                price_data[symbol] = self.db_manager.get_klines(
                    symbol=symbol,
                    timeframe=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É –∑ —Ü—ñ–Ω–∞–º–∏ –∑–∞–∫—Ä–∏—Ç—Ç—è –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤
            df = pd.DataFrame()
            for symbol, data in price_data.items():
                data['open_time'] = pd.to_datetime(data['open_time'], unit='s')  # –∞–±–æ unit='ms' ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä —Ñ–æ—Ä–º–∞—Ç
                data.set_index('open_time', inplace=True)
                df[symbol] = data['close']

            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ –¥–∞–Ω—ñ
            if df.isnull().values.any():
                missing_count = df.isnull().sum().sum()
                self.logger.warning(f"–í–∏—è–≤–ª–µ–Ω–æ {missing_count} –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö –∑–Ω–∞—á–µ–Ω—å. –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –º–µ—Ç–æ–¥–æ–º forward fill")
                df = df.fillna(method='ffill')

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            returns_df = df.pct_change(period)

            # –í–∏–¥–∞–ª–µ–Ω–Ω—è –ø–µ—Ä—à–∏—Ö —Ä—è–¥–∫—ñ–≤, —è–∫—ñ –º—ñ—Å—Ç—è—Ç—å NaN —á–µ—Ä–µ–∑ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            returns_df = returns_df.iloc[period:]

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–∞—Ç—Ä–∏—Ü—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            correlation_matrix = returns_df.corr(method=method)

            self.logger.info(f"–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ —É—Å–ø—ñ—à–Ω–æ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–∞ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –º–µ—Ç–æ–¥—É {method}")

            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É –±–∞–∑—É –¥–∞–Ω–∏—Ö
            self.save_correlation_to_db(
                correlation_matrix=correlation_matrix,
                correlation_type='returns',
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                method=method
            )

            return correlation_matrix

        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ: {str(e)}")
            raise

    def calculate_volatility_correlation(self, symbols: List[str],
                                         timeframe: str = None,
                                         start_time: Optional[datetime] = None,
                                         end_time: Optional[datetime] = None,
                                         window: int = None,
                                         method: str = None) -> pd.DataFrame:
        """
            –û–±—á–∏—Å–ª—é—î –º–∞—Ç—Ä–∏—Ü—é –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ –¥–ª—è –∑–∞–¥–∞–Ω–∏—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤.

            –í–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å –æ—Ü—ñ–Ω—é—î—Ç—å—Å—è —è–∫ –∫–æ–≤–∑–Ω–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ. –î–∞–Ω—ñ –±–µ—Ä—É—Ç—å—Å—è –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö,
            –æ–±—Ä–æ–±–ª—è—é—Ç—å—Å—è –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –∫–æ–≤–∑–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞ —ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó.

            Args:
                symbols (List[str]): –°–ø–∏—Å–æ–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ["BTC", "ETH"]).
                timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–∏—Ö (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1h"). –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
                start_time (datetime, optional): –ü–æ—á–∞—Ç–∫–æ–≤–∞ –¥–∞—Ç–∞ –ø–µ—Ä—ñ–æ–¥—É. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–Ω—è lookback –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
                end_time (datetime, optional): –ö—ñ–Ω—Ü–µ–≤–∞ –¥–∞—Ç–∞ –ø–µ—Ä—ñ–æ–¥—É. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –±–µ—Ä–µ—Ç—å—Å—è –ø–æ—Ç–æ—á–Ω–∞ –¥–∞—Ç–∞.
                window (int, optional): –†–æ–∑–º—ñ—Ä –∫–æ–≤–∑–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞ –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –±–µ—Ä–µ—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
                method (str, optional): –ú–µ—Ç–æ–¥ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó ('pearson', 'kendall', 'spearman').

            Returns:
                pd.DataFrame: –ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ –º—ñ–∂ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º–∏.
            """
        # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω—ñ
        timeframe = timeframe or self.config['default_timeframe']
        window = window or self.config['default_correlation_window']
        method = method or self.config['default_correlation_method']

        self.logger.info(
            f"–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ –¥–ª—è {len(symbols)} —Å–∏–º–≤–æ–ª—ñ–≤ –∑ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º {timeframe} —Ç–∞ –≤—ñ–∫–Ω–æ–º {window}")

        # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∫—ñ–Ω—Ü–µ–≤–æ–≥–æ —á–∞—Å—É —è–∫ –ø–æ—Ç–æ—á–Ω–∏–π, —è–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ
        end_time = end_time or datetime.now()

        # –Ø–∫—â–æ –ø–æ—á–∞—Ç–∫–æ–≤–∏–π —á–∞—Å –Ω–µ –≤–∫–∞–∑–∞–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
        if start_time is None:
            lookback_days = self.config['default_lookback_days']
            start_time = end_time - timedelta(days=lookback_days)
            self.logger.debug(f"–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–µ—Ä—ñ–æ–¥—É –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: {lookback_days} –¥–Ω—ñ–≤")

        try:
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ü—ñ–Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
            price_data = {}
            for symbol in symbols:
                self.logger.debug(f"–û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è {symbol}")
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ db_manager.get_klines –∑–∞–º—ñ—Å—Ç—å binance_client.get_historical_prices
                price_data[symbol] = self.db_manager.get_klines(
                    symbol=symbol,
                    timeframe=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É –∑ —Ü—ñ–Ω–∞–º–∏ –∑–∞–∫—Ä–∏—Ç—Ç—è –¥–ª—è –≤—Å—ñ—Ö —Å–∏–º–≤–æ–ª—ñ–≤
            price_df = pd.DataFrame()
            for symbol, data in price_data.items():
                data['open_time'] = pd.to_datetime(data['open_time'], unit='s')  # –∞–±–æ unit='ms' ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä —Ñ–æ—Ä–º–∞—Ç
                data.set_index('open_time', inplace=True)
                price_df[symbol] = data['close']

            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ –¥–∞–Ω—ñ
            if price_df.isnull().values.any():
                missing_count = price_df.isnull().sum().sum()
                self.logger.warning(f"–í–∏—è–≤–ª–µ–Ω–æ {missing_count} –≤—ñ–¥—Å—É—Ç–Ω—ñ—Ö –∑–Ω–∞—á–µ–Ω—å. –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –º–µ—Ç–æ–¥–æ–º forward fill")
                price_df = price_df.fillna(method='ffill')

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
            returns_df = price_df.pct_change()
            returns_df = returns_df.iloc[1:]  # –í–∏–¥–∞–ª–µ–Ω–Ω—è –ø–µ—Ä—à–æ–≥–æ —Ä—è–¥–∫–∞, —è–∫–∏–π –º—ñ—Å—Ç–∏—Ç—å NaN

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ)
            volatility_df = pd.DataFrame()
            for symbol in symbols:
                volatility_df[symbol] = returns_df[symbol].rolling(window=window).std()

            # –í–∏–¥–∞–ª–µ–Ω–Ω—è –ø–æ—á–∞—Ç–∫–æ–≤–∏—Ö —Ä—è–¥–∫—ñ–≤, —è–∫—ñ –º—ñ—Å—Ç—è—Ç—å NaN —á–µ—Ä–µ–∑ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ–≤–∑–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞
            volatility_df = volatility_df.iloc[window - 1:]

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–∞—Ç—Ä–∏—Ü—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ
            correlation_matrix = volatility_df.corr(method=method)

            self.logger.info(f"–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ —É—Å–ø—ñ—à–Ω–æ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–∞ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –º–µ—Ç–æ–¥—É {method}")

            # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É –±–∞–∑—É –¥–∞–Ω–∏—Ö
            self.save_correlation_to_db(
                correlation_matrix=correlation_matrix,
                correlation_type='volatility',
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                method=method
            )

            return correlation_matrix

        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ: {str(e)}")
            raise

    def get_correlated_pairs(self, correlation_matrix: pd.DataFrame,
                             threshold: float = None) -> List[Tuple[str, str, float]]:
        """
           –í–∏–∑–Ω–∞—á–∞—î –ø–∞—Ä–∏ –∞–∫—Ç–∏–≤—ñ–≤ —ñ–∑ —Å–∏–ª—å–Ω–æ—é –ø–æ–∑–∏—Ç–∏–≤–Ω–æ—é –∫–æ—Ä–µ–ª—è—Ü—ñ—î—é, —â–æ –ø–µ—Ä–µ–≤–∏—â—É—î –∑–∞–¥–∞–Ω–∏–π –ø–æ—Ä—ñ–≥.

           –ü–µ—Ä–µ–±–∏—Ä–∞—î –ª–∏—à–µ –≤–µ—Ä—Ö–Ω—ñ–π —Ç—Ä–∏–∫—É—Ç–Ω–∏–∫ –º–∞—Ç—Ä–∏—Ü—ñ, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –¥—É–±–ª—é–≤–∞–Ω–Ω—è —Ç–∞ —Å–∞–º–æ–∫–æ—Ä–µ–ª—è—Ü—ñ–π.

           Args:
               correlation_matrix (pd.DataFrame): –ö–≤–∞–¥—Ä–∞—Ç–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ–π –º—ñ–∂ –∞–∫—Ç–∏–≤–∞–º–∏.
               threshold (float, optional): –ü–æ—Ä—ñ–≥ –¥–ª—è —Å–∏–ª—å–Ω–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó. –Ø–∫—â–æ –Ω–µ –∑–∞–¥–∞–Ω–æ ‚Äî –±–µ—Ä–µ—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.

           Returns:
               List[Tuple[str, str, float]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂—ñ–≤ —É —Ñ–æ—Ä–º–∞—Ç—ñ (symbol1, symbol2, correlation),
               –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏—Ö –∑–∞ —Å–ø–∞–¥–∞–Ω–Ω—è–º –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó.
           """
        # Use default threshold from config if not specified
        threshold = threshold or self.config['correlation_threshold']

        # Initialize results list
        correlated_pairs = []

        # Get the symbols (assuming they are both column and index names)
        symbols = correlation_matrix.columns.tolist()

        # Iterate through upper triangle of correlation matrix
        for i in range(len(symbols)):
            for j in range(i + 1, len(symbols)):  # Start from i+1 to avoid duplicates and self-correlations
                symbol1, symbol2 = symbols[i], symbols[j]
                correlation = correlation_matrix.loc[symbol1, symbol2]

                # Check if correlation is above threshold
                if correlation >= threshold:
                    correlated_pairs.append((symbol1, symbol2, correlation))

        # Sort pairs by correlation value in descending order
        correlated_pairs.sort(key=lambda x: x[2], reverse=True)

        self.logger.info(f"Found {len(correlated_pairs)} highly correlated pairs with threshold {threshold}")
        return correlated_pairs

    def get_anticorrelated_pairs(self, correlation_matrix: pd.DataFrame,
                                 threshold: float = None) -> List[Tuple[str, str, float]]:
        """
           –í–∏–∑–Ω–∞—á–∞—î –ø–∞—Ä–∏ –∞–∫—Ç–∏–≤—ñ–≤ –∑ —Å–∏–ª—å–Ω–æ—é –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ—é –∫–æ—Ä–µ–ª—è—Ü—ñ—î—é, —â–æ –º–µ–Ω—à–µ –∞–±–æ –¥–æ—Ä—ñ–≤–Ω—é—î –ø–æ—Ä–æ–≥—É.

           –ü–µ—Ä–µ–±–∏—Ä–∞—î –ª–∏—à–µ –≤–µ—Ä—Ö–Ω—ñ–π —Ç—Ä–∏–∫—É—Ç–Ω–∏–∫ –º–∞—Ç—Ä–∏—Ü—ñ, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –¥—É–±–ª—é–≤–∞–Ω–Ω—è —Ç–∞ —Å–∞–º–æ–∫–æ—Ä–µ–ª—è—Ü—ñ–π.

           Args:
               correlation_matrix (pd.DataFrame): –ö–≤–∞–¥—Ä–∞—Ç–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ–π –º—ñ–∂ –∞–∫—Ç–∏–≤–∞–º–∏.
               threshold (float, optional): –ü–æ—Ä—ñ–≥ –¥–ª—è —Å–∏–ª—å–Ω–æ—ó –∞–Ω—Ç–∏–∫–æ—Ä–µ–ª—è—Ü—ñ—ó (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, -0.8). –Ø–∫—â–æ –Ω–µ –∑–∞–¥–∞–Ω–æ ‚Äî –±–µ—Ä–µ—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.

           Returns:
               List[Tuple[str, str, float]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂—ñ–≤ —É —Ñ–æ—Ä–º–∞—Ç—ñ (symbol1, symbol2, correlation),
               –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏—Ö –∑–∞ –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è–º (–Ω–∞–π–±—ñ–ª—å—à –Ω–µ–≥–∞—Ç–∏–≤–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è ‚Äî –ø–µ—Ä—à–∞).
           """
        # Use default threshold from config if not specified
        threshold = threshold or self.config['anticorrelation_threshold']

        # Initialize results list
        anticorrelated_pairs = []

        # Get the symbols (assuming they are both column and index names)
        symbols = correlation_matrix.columns.tolist()

        # Iterate through upper triangle of correlation matrix
        for i in range(len(symbols)):
            for j in range(i + 1, len(symbols)):  # Start from i+1 to avoid duplicates and self-correlations
                symbol1, symbol2 = symbols[i], symbols[j]
                correlation = correlation_matrix.loc[symbol1, symbol2]

                # Check if correlation is below threshold (negative correlation)
                if correlation <= threshold:
                    anticorrelated_pairs.append((symbol1, symbol2, correlation))

        # Sort pairs by correlation value in ascending order (most negative first)
        anticorrelated_pairs.sort(key=lambda x: x[2])

        self.logger.info(f"Found {len(anticorrelated_pairs)} highly anti-correlated pairs with threshold {threshold}")
        return anticorrelated_pairs

    def calculate_rolling_correlation(self, symbol1: str, symbol2: str,
                                      timeframe: str = None,
                                      start_time: Optional[datetime] = None,
                                      end_time: Optional[datetime] = None,
                                      window: int = None,
                                      method: str = None) -> pd.Series:
        """
            –û–±—á–∏—Å–ª—é—î –∫–æ–≤–∑–Ω—É (rolling) –∫–æ—Ä–µ–ª—è—Ü—ñ—é –º—ñ–∂ –¥–≤–æ–º–∞ –∞–∫—Ç–∏–≤–∞–º–∏ –∑–∞ –≤–∫–∞–∑–∞–Ω–∏–π –ø–µ—Ä—ñ–æ–¥ —á–∞—Å—É.

            –î–∞–Ω—ñ –±–µ—Ä—É—Ç—å—Å—è –∑ –±–∞–∑–∏, –≤–∏—Ä—ñ–≤–Ω—é—é—Ç—å—Å—è —É —á–∞—Å—ñ —Ç–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—é—Ç—å—Å—è —É –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ, –ø—ñ—Å–ª—è —á–æ–≥–æ
            –æ–±—á–∏—Å–ª—é—î—Ç—å—Å—è –∫–æ–≤–∑–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è.

            Args:
                symbol1 (str): –ü–µ—Ä—à–∏–π —Å–∏–º–≤–æ–ª (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "BTC").
                symbol2 (str): –î—Ä—É–≥–∏–π —Å–∏–º–≤–æ–ª (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "ETH").
                timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1h"). –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –±–µ—Ä–µ—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
                start_time (datetime, optional): –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä—ñ–æ–¥—É. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –≤–∏–∑–Ω–∞—á–∞—î—Ç—å—Å—è –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º `window` —ñ –±—É—Ñ–µ—Ä–∞.
                end_time (datetime, optional): –ö—ñ–Ω–µ—Ü—å –ø–µ—Ä—ñ–æ–¥—É. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –±–µ—Ä–µ—Ç—å—Å—è –ø–æ—Ç–æ—á–Ω–∏–π —á–∞—Å.
                window (int, optional): –†–æ–∑–º—ñ—Ä –∫–æ–≤–∑–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –±–µ—Ä–µ—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
                method (str, optional): –ú–µ—Ç–æ–¥ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (—Ç—ñ–ª—å–∫–∏ 'pearson' –Ω–∞—Ä–∞–∑—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è).

            Returns:
                pd.Series: –°–µ—Ä—ñ—è –∫–æ–≤–∑–Ω–∏—Ö –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –ø–æ —á–∞—Å–æ–≤—ñ–π —à–∫–∞–ª—ñ.
            """
        # Use default values from config if not specified
        timeframe = timeframe or self.config['default_timeframe']
        window = window or self.config['default_correlation_window']
        method = method or self.config['default_correlation_method']

        # Set default time range if not specified
        if end_time is None:
            end_time = datetime.now()
        if start_time is None:
            # Add extra data to accommodate the window size
            start_time = end_time - timedelta(days=window + 30)  # +30 days buffer

        self.logger.info(f"Calculating rolling correlation between {symbol1} and {symbol2} with window={window}")

        try:
            # Fetch price data for both symbols
            df1 = self.db_manager.get_klines(
                symbol=symbol1,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time
            )

            df2 = self.db_manager.get_klines(
                symbol=symbol2,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time
            )

            # Extract close prices
            price1 = df1['close']
            price2 = df2['close']

            # Align the time series (handle missing data points)
            aligned_prices = pd.DataFrame({
                symbol1: price1,
                symbol2: price2
            })

            # Calculate percent changes (returns)
            returns = aligned_prices.pct_change().dropna()

            # Calculate rolling correlation (method='pearson' only)
            rolling_corr = returns[symbol1].rolling(window=window).corr(returns[symbol2])

            self.logger.info(f"Successfully calculated rolling correlation with {len(rolling_corr)} data points")
            return rolling_corr

        except Exception as e:
            self.logger.error(f"Error calculating rolling correlation: {str(e)}")
            raise

    def detect_correlation_breakdowns(self, symbol1: str, symbol2: str,
                                      timeframe: str = None,
                                      start_time: Optional[datetime] = None,
                                      end_time: Optional[datetime] = None,
                                      window: int = None,
                                      threshold: float = None) -> List[datetime]:
        """
           –í–∏—è–≤–ª—è—î –º–æ–º–µ–Ω—Ç–∏ –∑–Ω–∞—á–Ω–æ–≥–æ —Ä–æ–∑—Ä–∏–≤—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ –¥–≤–æ–º–∞ –∞–∫—Ç–∏–≤–∞–º–∏.

           –ú–µ—Ç–æ–¥ –æ–±—á–∏—Å–ª—é—î –∫–æ–≤–∑–Ω—É –∫–æ—Ä–µ–ª—è—Ü—ñ—é, –≤–∏—è–≤–ª—è—î —Ä—ñ–∑–∫—ñ –∑–º—ñ–Ω–∏, —â–æ –ø–µ—Ä–µ–≤–∏—â—É—é—Ç—å –ø–æ—Ä—ñ–≥,
           —ñ –∑–±–µ—Ä—ñ–≥–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ü—ñ —Ä–æ–∑—Ä–∏–≤–∏ —É –±–∞–∑—É –¥–∞–Ω–∏—Ö.

           Args:
               symbol1 (str): –ü–µ—Ä—à–∏–π —Å–∏–º–≤–æ–ª (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "ETH").
               symbol2 (str): –î—Ä—É–≥–∏–π —Å–∏–º–≤–æ–ª (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "BTC").
               timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥ "1d". –Ø–∫—â–æ –Ω–µ –∑–∞–¥–∞–Ω–æ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º.
               start_time (datetime, optional): –ü–æ—á–∞—Ç–∫–æ–≤–∞ –¥–∞—Ç–∞ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.
               end_time (datetime, optional): –ö—ñ–Ω—Ü–µ–≤–∞ –¥–∞—Ç–∞ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.
               window (int, optional): –†–æ–∑–º—ñ—Ä –∫–æ–≤–∑–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞.
               threshold (float, optional): –ü–æ—Ä—ñ–≥ –¥–ª—è –∑–º—ñ–Ω–∏ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó, —è–∫–∞ –≤–≤–∞–∂–∞—î—Ç—å—Å—è —Ä–æ–∑—Ä–∏–≤–æ–º.

           Returns:
               List[datetime]: –°–ø–∏—Å–æ–∫ –º—ñ—Ç–æ–∫ —á–∞—Å—É, –¥–µ –≤–∏—è–≤–ª–µ–Ω–æ —Ä–æ–∑—Ä–∏–≤ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó.
           """
        # Use default values from config if not specified
        timeframe = timeframe or self.config['default_timeframe']
        window = window or self.config['default_correlation_window']
        threshold = threshold or self.config['breakdown_threshold']

        self.logger.info(f"Detecting correlation breakdowns between {symbol1} and {symbol2} with threshold {threshold}")

        try:
            # Calculate rolling correlation between the two symbols
            rolling_corr = self.calculate_rolling_correlation(
                symbol1=symbol1,
                symbol2=symbol2,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                window=window
            )

            # Calculate absolute changes in correlation
            correlation_changes = rolling_corr.diff().abs()

            # Identify points where correlation changes more than the threshold
            breakdown_points = correlation_changes[correlation_changes > threshold].index.tolist()

            self.logger.info(f"Found {len(breakdown_points)} correlation breakdown points")

            # Save breakdown data to database
            breakdown_data = []
            for point in breakdown_points:
                correlation_before = rolling_corr.loc[rolling_corr.index < point].iloc[-1] if not rolling_corr.loc[
                    rolling_corr.index < point].empty else None
                correlation_after = rolling_corr.loc[point]
                change_magnitude = correlation_changes.loc[point]

                breakdown_data.append({
                    'timestamp': pd.to_datetime(point).to_pydatetime(),  # üîß –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –¥–æ datetime.datetime
                    'symbol1': symbol1,
                    'symbol2': symbol2,
                    'correlation_before': correlation_before,
                    'correlation_after': correlation_after,
                    'change_magnitude': change_magnitude
                })

            # Save to correlation_breakdowns table
            if breakdown_data:
                for point_data in breakdown_data:
                    self.db_manager.save_correlation_breakdown(
                        breakdown_time=point_data['timestamp'],
                        symbol1=point_data['symbol1'],
                        symbol2=point_data['symbol2'],
                        correlation_before=point_data['correlation_before'],
                        correlation_after=point_data['correlation_after'],
                        method=self.config.get('default_correlation_method', 'pearson'),
                        threshold=threshold,
                        timeframe=timeframe,
                        window_size=window
                    )
                self.logger.debug(f"Saved {len(breakdown_data)} breakdown points to database")

            return breakdown_points

        except Exception as e:
            self.logger.error(f"Error detecting correlation breakdowns: {str(e)}")
            raise

    def calculate_market_beta(self, symbol: str, market_symbol: str = 'BTC',
                              timeframe: str = None,
                              start_time: Optional[datetime] = None,
                              end_time: Optional[datetime] = None,
                              window: int = None) -> Union[float, pd.Series]:
        """
           –û–±—á–∏—Å–ª—é—î –±–µ—Ç–∞-–∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∞–∫—Ç–∏–≤—É –≤—ñ–¥–Ω–æ—Å–Ω–æ —Ä–∏–Ω–∫—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, BTC).

           –Ø–∫—â–æ –∑–∞–¥–∞–Ω–æ `window`, –æ–±—á–∏—Å–ª—é—î—Ç—å—Å—è –∫–æ–≤–∑–Ω–µ –±–µ—Ç–∞; —ñ–Ω–∞–∫—à–µ ‚Äî –∑–∞–≥–∞–ª—å–Ω–µ –±–µ—Ç–∞ –∑–∞ –≤–µ—Å—å –ø–µ—Ä—ñ–æ–¥.
           –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ –±–∞–∑—É –¥–∞–Ω–∏—Ö.

           Args:
               symbol (str): –°–∏–º–≤–æ–ª –∞–∫—Ç–∏–≤—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "ETH").
               market_symbol (str, optional): –°–∏–º–≤–æ–ª —Ä–∏–Ω–∫—É –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è. –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º ‚Äî "BTC".
               timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1d").
               start_time (datetime, optional): –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä—ñ–æ–¥—É –∞–Ω–∞–ª—ñ–∑—É.
               end_time (datetime, optional): –ö—ñ–Ω–µ—Ü—å –ø–µ—Ä—ñ–æ–¥—É –∞–Ω–∞–ª—ñ–∑—É.
               window (int, optional): –†–æ–∑–º—ñ—Ä –∫–æ–≤–∑–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞ –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è rolling beta.

           Returns:
               Union[float, pd.Series]: –ó–∞–≥–∞–ª—å–Ω–∏–π –±–µ—Ç–∞-–∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∞–±–æ —Å–µ—Ä—ñ—è –∫–æ–≤–∑–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å –±–µ—Ç–∞.
           """
        # Use default values from config if not specified
        timeframe = timeframe or self.config['default_timeframe']
        window = window or self.config['default_correlation_window']

        self.logger.info(f"Calculating market beta for {symbol} relative to {market_symbol}")

        # Set default time range if not specified
        end_time = end_time or datetime.now()
        if start_time is None:
            lookback_days = self.config['default_lookback_days']
            start_time = end_time - timedelta(days=lookback_days)

        try:
            # Fetch price data for asset and market benchmark
            asset_data = self.db_manager.get_klines(
                symbol=symbol,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time
            )

            market_data = self.db_manager.get_klines(
                symbol=market_symbol,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time
            )

            # Calculate returns and convert to float immediately
            asset_prices = asset_data['close'].astype(float)
            market_prices = market_data['close'].astype(float)

            # Align time series
            df = pd.DataFrame({
                'asset': asset_prices,
                'market': market_prices
            })

            # Calculate returns
            returns = df.pct_change().dropna()

            # If window is specified, calculate rolling beta
            if window:
                # Calculate rolling covariance and market variance
                rolling_cov = returns['asset'].rolling(window=window).cov(returns['market'])
                rolling_market_var = returns['market'].rolling(window=window).var()

                # Calculate rolling beta
                rolling_beta = rolling_cov / rolling_market_var

                # Save beta time series to database
                beta_records = []
                for timestamp, beta_value in rolling_beta.items():
                    if not np.isnan(beta_value) and not np.isinf(beta_value):
                        beta_records.append({
                            'timestamp': timestamp,
                            'symbol': symbol,
                            'market_symbol': market_symbol,
                            'beta': float(beta_value),  # Ensure beta is float
                            'timeframe': timeframe,
                            'window': window
                        })

                # Save to beta_time_series table
                if beta_records:
                    timestamps = [record['timestamp'] for record in beta_records]
                    beta_values = [record['beta'] for record in beta_records]

                    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ pd.Timestamp —É datetime.datetime
                    timestamps = [ts.to_pydatetime() if isinstance(ts, pd.Timestamp) else ts for ts in timestamps]

                    self.db_manager.save_beta_time_series(
                        symbol=symbol,
                        market_symbol=market_symbol,
                        timestamps=timestamps,
                        beta_values=beta_values,
                        timeframe=timeframe,
                        window_size=window
                    )

                    self.logger.debug(f"Saved {len(beta_records)} beta values to database")

                return rolling_beta
            else:
                # Calculate overall beta
                beta = np.cov(returns['asset'], returns['market'])[0, 1] / np.var(returns['market'])

                # Save to market_betas table
                beta_record = {
                    'symbol': symbol,
                    'market_symbol': market_symbol,
                    'beta': float(beta),  # Ensure beta is float
                    'timeframe': timeframe,
                    'start_time': start_time,
                    'end_time': end_time,
                }

                self.db_manager.save_market_beta([beta_record])
                self.logger.info(f"Saved beta value {beta} for {symbol} to database")

                return beta

        except Exception as e:
            self.logger.error(f"Error calculating market beta for {symbol}: {str(e)}")
            raise


    def save_correlation_to_db(self, correlation_matrix: pd.DataFrame,
                               correlation_type: str,
                               timeframe: str,
                               start_time: datetime,
                               end_time: datetime,
                               method: str) -> bool:
        """
            –ó–±–µ—Ä—ñ–≥–∞—î –º–∞—Ç—Ä–∏—Ü—é –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ç–∞ –ø–∞—Ä–∏ –∑ –≤–∏—Å–æ–∫–æ—é –∫–æ—Ä–µ–ª—è—Ü—ñ—î—é –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö.

            –°—Ç–≤–æ—Ä—é—î —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä –º–∞—Ç—Ä–∏—Ü—ñ, —Å–µ—Ä—ñ–∞–ª—ñ–∑—É—î –¥–∞–Ω—ñ, –æ–±—á–∏—Å–ª—é—î –ø–∞—Ä–∏ –∑ –∞–±—Å–æ–ª—é—Ç–Ω–æ—é –∫–æ—Ä–µ–ª—è—Ü—ñ—î—é –≤–∏—â–µ –ø–æ—Ä–æ–≥—É
            —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î —Ü—ñ –¥–∞–Ω—ñ –≤ –±–∞–∑—É.

            Args:
                correlation_matrix (pd.DataFrame): –ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó.
                correlation_type (str): –¢–∏–ø –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "pearson").
                timeframe (str): –¢–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1d").
                start_time (datetime): –ü–æ—á–∞—Ç–æ–∫ –∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ–≥–æ –ø–µ—Ä—ñ–æ–¥—É.
                end_time (datetime): –ö—ñ–Ω–µ—Ü—å –∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ–≥–æ –ø–µ—Ä—ñ–æ–¥—É.
                method (str): –ú–µ—Ç–æ–¥ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "pearson").

            Returns:
                bool: –ü–æ–≤–µ—Ä—Ç–∞—î True, —è–∫—â–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É—Å–ø—ñ—à–Ω–µ; —ñ–Ω–∞–∫—à–µ False.
            """
        # Use default method from config if not specified
        method = method or self.config['default_correlation_method']

        self.logger.info(f"Saving {correlation_type} correlation matrix to database")

        try:
            # Create a record for the correlation matrix
            matrix_id = f"{correlation_type}_{timeframe}_{start_time.strftime('%Y%m%d')}_{end_time.strftime('%Y%m%d')}_{method}"

            # Prepare data for the correlation_matrices table
            matrix_data = {
                'matrix_id': matrix_id,
                'correlation_type': correlation_type,
                'timeframe': timeframe,
                'start_time': start_time,
                'end_time': end_time,
                'method': method,
                'analysis_time': datetime.now(),
                'symbols': correlation_matrix.columns.tolist(),
                'matrix_json': correlation_matrix.to_json()
            }

            # Save to correlation_matrices table
            self.db_manager.save_correlation_matrix(
                correlation_matrix.columns.tolist(),
                correlation_type,
                timeframe,
                start_time,
                end_time=end_time,
                method='pearson'
            )
            # Extract and save highly correlated pairs
            symbols = correlation_matrix.columns.tolist()
            pairs_data = []

            for i in range(len(symbols)):
                for j in range(i + 1, len(symbols)):
                    symbol1, symbol2 = symbols[i], symbols[j]
                    correlation = correlation_matrix.loc[symbol1, symbol2]

                    if abs(correlation) >= self.config['correlation_threshold']:
                        pair_data = {
                            'matrix_id': matrix_id,
                            'symbol1': symbol1,
                            'symbol2': symbol2,
                            'correlation_value': correlation,  # Changed from 'correlation'
                            'correlation_type': correlation_type,
                            'timeframe': timeframe,
                            'start_time': start_time,  # Added
                            'end_time': end_time,  # Added
                            'method': method,  # Added
                            'analysis_time': datetime.now()
                        }
                        pairs_data.append(pair_data)

            # Save to correlated_pairs table
            if pairs_data:
                self.db_manager.insert_correlated_pair(pairs_data,method='pearson')
                self.logger.debug(f"Saved {len(pairs_data)} correlated pairs to database")

            self.logger.info(f"Successfully saved correlation matrix with ID {matrix_id}")
            return True

        except Exception as e:
            self.logger.error(f"Error saving correlation to database: {str(e)}")
            return False

    def load_correlation_from_db(self, correlation_type: str,
                                 timeframe: str,
                                 start_time: datetime,
                                 end_time: datetime,
                                 method: str = None) -> Optional[pd.DataFrame]:
        """
           –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∑–±–µ—Ä–µ–∂–µ–Ω—É –º–∞—Ç—Ä–∏—Ü—é –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö –∑–∞ –∑–∞–¥–∞–Ω–∏–º –ø–µ—Ä—ñ–æ–¥–æ–º —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

           –§–æ—Ä–º—É—î —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π `matrix_id` –¥–ª—è –¥–æ—Å—Ç—É–ø—É –¥–æ –∑–∞–ø–∏—Å—É, –∑—á–∏—Ç—É—î JSON-—Ä—è–¥–æ–∫ –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö —ñ –¥–µ—Å–µ—Ä—ñ–∞–ª—ñ–∑—É—î –π–æ–≥–æ –≤ DataFrame.

           Args:
               correlation_type (str): –¢–∏–ø –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "pearson", "spearman").
               timeframe (str): –¢–∞–π–º—Ñ—Ä–µ–π–º, –∑–∞ —è–∫–∏–º –±—É–ª–∞ –ø–æ–±—É–¥–æ–≤–∞–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1d").
               start_time (datetime): –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä—ñ–æ–¥—É –∞–Ω–∞–ª—ñ–∑—É.
               end_time (datetime): –ö—ñ–Ω–µ—Ü—å –ø–µ—Ä—ñ–æ–¥—É –∞–Ω–∞–ª—ñ–∑—É.
               method (str, optional): –ú–µ—Ç–æ–¥ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó. –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.

           Returns:
               Optional[pd.DataFrame]: –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –∞–±–æ `None`, —è–∫—â–æ –¥–∞–Ω—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —á–∏ –≤–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞.
           """
        # Use default method from config if not specified
        method = method or self.config['default_correlation_method']

        self.logger.info(f"Loading {correlation_type} correlation matrix from database")

        try:
            # Create the matrix ID for lookup
            matrix_id = f"{correlation_type}_{timeframe}_{start_time.strftime('%Y%m%d')}_{end_time.strftime('%Y%m%d')}_{method}"

            # Load from correlation_matrices table
            matrix_data = self.db_manager.get_correlation_matrix(matrix_id)

            if matrix_data:
                # Convert JSON string back to DataFrame
                matrix_json = matrix_data.get('matrix_json')
                if matrix_json:
                    correlation_matrix = pd.read_json(matrix_json)
                    self.logger.info(f"Successfully loaded correlation matrix with ID {matrix_id}")
                    return correlation_matrix

            self.logger.warning(f"No correlation matrix found with ID {matrix_id}")
            return None

        except Exception as e:
            self.logger.error(f"Error loading correlation from database: {str(e)}")
            return None

    def correlation_time_series(self, symbols_pair: Tuple[str, str],
                                correlation_window: int = None,
                                lookback_days: int = None,
                                timeframe: str = None) -> pd.Series:
        """
           –û–±—á–∏—Å–ª—é—î –∞–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î –∑ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö —á–∞—Å–æ–≤–∏–π —Ä—è–¥ –∫–æ–≤–∑–Ω–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ –¥–≤–æ–º–∞ —Å–∏–º–≤–æ–ª–∞–º–∏.

           –Ø–∫—â–æ –¥–∞–Ω—ñ –≤–∂–µ —î –≤ –±–∞–∑—ñ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –≤–æ–Ω–∏. –Ü–Ω–∞–∫—à–µ –∫–æ—Ä–µ–ª—è—Ü—ñ—è –æ–±—á–∏—Å–ª—é—î—Ç—å—Å—è —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è.

           Args:
               symbols_pair (Tuple[str, str]): –ü–∞—Ä–∞ —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó (symbol1, symbol2).
               correlation_window (int, optional): –†–æ–∑–º—ñ—Ä –≤—ñ–∫–Ω–∞ –¥–ª—è –∫–æ–≤–∑–Ω–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó. –Ø–∫—â–æ –Ω–µ –∑–∞–¥–∞–Ω–æ, –±–µ—Ä–µ—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
               lookback_days (int, optional): –ü–µ—Ä—ñ–æ–¥ –∑–≤–æ—Ä–æ—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≥–ª—è–¥—É –≤ –¥–Ω—è—Ö –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.
               timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1d", "1h").

           Returns:
               pd.Series: –ß–∞—Å–æ–≤–∏–π —Ä—è–¥ –∫–æ–≤–∑–Ω–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ –∞–∫—Ç–∏–≤–∞–º–∏.
           """
        # Use default values from config if not specified
        correlation_window = correlation_window or self.config['default_correlation_window']
        lookback_days = lookback_days or self.config['default_lookback_days']
        timeframe = timeframe or self.config['default_timeframe']

        symbol1, symbol2 = symbols_pair
        self.logger.info(f"Calculating correlation time series between {symbol1} and {symbol2}")

        # Set time range
        end_time = datetime.now()
        start_time = end_time - timedelta(days=lookback_days)

        try:
            # First check if we already have this data in the database
            correlation_series = self.db_manager.get_correlation_time_series(
                symbol1=symbol1,
                symbol2=symbol2,
                start_time=start_time,
                end_time=end_time,
                timeframe=timeframe,
                window=correlation_window
            )

            if correlation_series is not None and not correlation_series.empty:
                self.logger.info(f"Found existing correlation time series in database")
                return correlation_series

            # If not found in database, calculate it
            self.logger.info(f"Calculating new correlation time series")

            # Calculate rolling correlation
            rolling_corr = self.calculate_rolling_correlation(
                symbol1=symbol1,
                symbol2=symbol2,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                window=correlation_window
            )

            # Save correlation time series to database
            correlation_data = []
            for timestamp, corr_value in rolling_corr.items():
                if not np.isnan(corr_value):
                    correlation_data.append({
                        'timestamp': timestamp,
                        'symbol1': symbol1,
                        'symbol2': symbol2,
                        'correlation': corr_value,
                        'timeframe': timeframe,
                        'window': correlation_window
                    })

            # Save to correlation_time_series table
            if correlation_data:
                self.db_manager.save_correlation_time_series(correlation_data,method='pearson')
                self.logger.debug(f"Saved {len(correlation_data)} correlation values to database")

            return rolling_corr

        except Exception as e:
            self.logger.error(f"Error calculating correlation time series: {str(e)}")
            raise

    def find_leading_indicators(self, target_symbol: str,
                                candidate_symbols: List[str],
                                lag_periods: List[int] = None,
                                timeframe: str = None,
                                start_time: Optional[datetime] = None,
                                end_time: Optional[datetime] = None) -> Dict[str, Dict[int, float]]:
        """
            –ê–Ω–∞–ª—ñ–∑—É—î —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤ –Ω–∞ —Ä–æ–ª—å –ª—ñ–¥–µ—Ä—ñ–≤ –¥–ª—è –∑–∞–¥–∞–Ω–æ–≥–æ —Ü—ñ–ª—å–æ–≤–æ–≥–æ —Å–∏–º–≤–æ–ª—É –∑–∞ –ª–∞–≥–∞–º–∏ —É –¥–æ—Ö—ñ–¥–Ω–æ—Å—Ç—ñ.

            –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –æ–±—á–∏—Å–ª—é—î—Ç—å—Å—è –∫–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ –ª–∞–≥–æ–≤–∞–Ω–∏–º–∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏ —Ç–∞ –¥–æ—Ö–æ–¥–Ω—ñ—Å—Ç—é —Ü—ñ–ª—å–æ–≤–æ–≥–æ –∞–∫—Ç–∏–≤—É.
            –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ –±–∞–∑—É –¥–∞–Ω–∏—Ö, —è–∫—â–æ —î –¥–æ—Å—Ç–∞—Ç–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∞–ª—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö.

            Args:
                target_symbol (str): –°–∏–º–≤–æ–ª, –¥–ª—è —è–∫–æ–≥–æ —à—É–∫–∞—é—Ç—å—Å—è –ª—ñ–¥–µ—Ä–∏.
                candidate_symbols (List[str]): –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤.
                lag_periods (List[int], optional): –ü–µ—Ä–µ–ª—ñ–∫ –ª–∞–≥—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ (–≤ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∫—Ä–æ–∫—ñ–≤ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É).
                timeframe (str, optional): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1d").
                start_time (datetime, optional): –ü–æ—á–∞—Ç–∫–æ–≤–∏–π —á–∞—Å –∞–Ω–∞–ª—ñ–∑—É.
                end_time (datetime, optional): –ö—ñ–Ω—Ü–µ–≤–∏–π —á–∞—Å –∞–Ω–∞–ª—ñ–∑—É.

            Returns:
                Dict[str, Dict[int, float]]: –°–ª–æ–≤–Ω–∏–∫, –¥–µ –∫–ª—é—á ‚Äî —Å–∏–º–≤–æ–ª-–∫–∞–Ω–¥–∏–¥–∞—Ç, –∞ –∑–Ω–∞—á–µ–Ω–Ω—è ‚Äî —Å–ª–æ–≤–Ω–∏–∫ –∑ –ª–∞–≥–∞–º–∏ —Ç–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º–∏ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∞–º–∏ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó.
            """
        # Use default values from config if not specified
        lag_periods = lag_periods or self.config['default_lag_periods']
        timeframe = timeframe or self.config['default_timeframe']

        self.logger.info(f"Finding leading indicators for {target_symbol} among {len(candidate_symbols)} candidates")

        # Set default time range if not specified
        end_time = end_time or datetime.now()
        if start_time is None:
            lookback_days = self.config['default_lookback_days']
            start_time = end_time - timedelta(days=lookback_days)

        try:
            # Fetch target data
            target_data = self.db_manager.get_klines(
                symbol=target_symbol,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time
            )

            # Calculate target returns
            target_prices = target_data['close']
            target_returns = target_prices.pct_change().dropna()

            # Dictionary to store results
            leading_indicators = {}
            leading_indicators_records = []

            # Test each candidate symbol
            for symbol in candidate_symbols:
                if symbol == target_symbol:
                    continue

                self.logger.debug(f"Testing {symbol} as a leading indicator")

                # Fetch candidate data
                candidate_data = self.db_manager.get_klines(
                    symbol=symbol,
                    timeframe=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )

                # Calculate candidate returns
                candidate_prices = candidate_data['close']
                candidate_returns = candidate_prices.pct_change().dropna()

                # Align time series
                common_index = target_returns.index.intersection(candidate_returns.index)
                if len(common_index) < max(lag_periods) + 10:  # Need enough data points
                    self.logger.warning(f"Insufficient aligned data points for {symbol}")
                    continue

                aligned_target = target_returns.loc[common_index]
                aligned_candidate = candidate_returns.loc[common_index]

                # Calculate lagged correlations
                lag_correlations = {}
                for lag in lag_periods:
                    # Shift candidate data forward to test if it leads target
                    lagged_candidate = aligned_candidate.shift(lag)

                    # Remove NaN values created by shifting
                    valid_indices = aligned_target.index.intersection(lagged_candidate.dropna().index)
                    if len(valid_indices) < 10:  # Need enough data points for correlation
                        continue

                    # Calculate correlation between target and lagged candidate
                    correlation = aligned_target.loc[valid_indices].corr(lagged_candidate.loc[valid_indices])
                    lag_correlations[lag] = correlation

                    # Add to records for database
                    leading_indicators_records.append({
                        'target_symbol': target_symbol,
                        'indicator_symbol': symbol,
                        'lag_period': lag,
                        'correlation_value': correlation,
                        'timeframe': timeframe,
                        'start_time': start_time,
                        'end_time': end_time,
                        'analysis_time': datetime.now(),
                        'method': 'pearson'
                    })

                # Only add to results if at least one lag period had a correlation
                if lag_correlations:
                    leading_indicators[symbol] = lag_correlations

            # Save to leading_indicators table
            if leading_indicators_records:
                self.db_manager.save_leading_indicators(leading_indicators_records)
                self.logger.debug(f"Saved {len(leading_indicators_records)} leading indicator records to database")

            return leading_indicators

        except Exception as e:
            self.logger.error(f"Error finding leading indicators: {str(e)}")
            raise

    def correlated_movement_prediction(self, symbol: str,
                                       correlated_symbols: List[str],
                                       prediction_horizon: int = None,
                                       timeframe: str = None) -> Dict[str, float]:
        """
            –ü—Ä–æ–≥–Ω–æ–∑—É—î –º–∞–π–±—É—Ç–Ω—ñ–π –Ω–∞–ø—Ä—è–º–æ–∫ —Ä—É—Ö—É —Ü—ñ–Ω–∏ –∑–∞–¥–∞–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É (symbol) –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –ø—Ä–∏–±—É—Ç–∫—ñ–≤
            —Å–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –ª—ñ–Ω—ñ–π–Ω—É —Ä–µ–≥—Ä–µ—Å—ñ—é.

            Parameters
            ----------
            symbol : str
                –û—Å–Ω–æ–≤–Ω–∏–π —Å–∏–º–≤–æ–ª (–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞), –¥–ª—è —è–∫–æ–≥–æ –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –ø—Ä–æ–≥–Ω–æ–∑.
            correlated_symbols : List[str]
                –°–ø–∏—Å–æ–∫ —Å–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤, —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è —è–∫ –æ–∑–Ω–∞–∫–∏.
            prediction_horizon : int, optional
                –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑—É —É –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø–µ—Ä—ñ–æ–¥—ñ–≤ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–Ω—ñ–≤). –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –±–µ—Ä–µ—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.
            timeframe : str, optional
                –¢–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, '1d', '4h'). –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º.

            Returns
            -------
            Dict[str, Union[float, str, Dict[str, float], datetime]]
                –°–ª–æ–≤–Ω–∏–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≥–Ω–æ–∑—É, —â–æ –≤–∫–ª—é—á–∞—î:
                - symbol : —Å–∏–º–≤–æ–ª –∞–∫—Ç–∏–≤—É
                - current_price : –ø–æ—Ç–æ—á–Ω–∞ —Ü—ñ–Ω–∞
                - predicted_return : –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–µ –≤—ñ–¥—Å–æ—Ç–∫–æ–≤–µ –∑–º—ñ–Ω–µ–Ω–Ω—è —Ü—ñ–Ω–∏
                - predicted_price : –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ —Ü—ñ–Ω–∞
                - prediction_horizon : –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑—É
                - prediction_direction : –Ω–∞–ø—Ä—è–º–æ–∫ ("up" –∞–±–æ "down")
                - confidence : –¥–æ–≤—ñ—Ä–∞ –¥–æ –ø—Ä–æ–≥–Ω–æ–∑—É (0‚Äì1)
                - model_r2 : –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –¥–µ—Ç–µ—Ä–º—ñ–Ω–∞—Ü—ñ—ó R¬≤
                - top_indicators : —Ç–æ–ø-5 –æ–∑–Ω–∞–∫ –∑–∞ –≤–∞–≥–æ–º—ñ—Å—Ç—é
                - prediction_timestamp : –¥–∞—Ç–∞ —Ç–∞ —á–∞—Å –ø—Ä–æ–≥–Ω–æ–∑—É

                –£ —Ä–∞–∑—ñ –ø–æ–º–∏–ª–∫–∏ –ø–æ–≤–µ—Ä—Ç–∞—î: {"error": "—Ç–µ–∫—Å—Ç –ø–æ–º–∏–ª–∫–∏"}
            """
        # Use default values from config if not specified
        prediction_horizon = prediction_horizon or self.config['default_prediction_horizon']
        timeframe = timeframe or self.config['default_timeframe']

        self.logger.info(
            f"Predicting movement for {symbol} using {len(correlated_symbols)} correlated symbols with horizon {prediction_horizon}")

        # Set default time range - we need more historical data for training
        end_time = datetime.now()
        lookback_days = self.config['default_lookback_days'] * 2  # Double the usual lookback for better training
        start_time = end_time - timedelta(days=lookback_days)

        try:
            # Fetch price data for target and all correlated symbols
            all_symbols = [symbol] + correlated_symbols
            price_data = {}
            for sym in all_symbols:
                price_data[sym] = self.db_manager.get_klines(
                    symbol=sym,
                    timeframe=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )

            # Extract close prices and convert to float
            close_prices = {}
            for sym, data in price_data.items():
                # Convert Decimal to float if needed
                close_prices[sym] = pd.Series(data['close']).astype(float)

            # Calculate returns
            returns = {}
            for sym, prices in close_prices.items():
                returns[sym] = prices.pct_change().dropna()

            # Create a dataframe with all returns
            all_returns = pd.DataFrame({sym: ret for sym, ret in returns.items()})

            # Handle any missing data
            if all_returns.isnull().values.any():
                missing_count = all_returns.isnull().sum().sum()
                self.logger.warning(f"Found {missing_count} missing values in returns. Filling with forward fill.")
                all_returns = all_returns.fillna(method='ffill')

            # Create prediction features by shifting correlated symbols' returns
            feature_df = pd.DataFrame()
            for i, corr_sym in enumerate(correlated_symbols):
                for lag in range(1, prediction_horizon + 1):
                    feature_name = f"{corr_sym}_lag_{lag}"
                    feature_df[feature_name] = all_returns[corr_sym].shift(lag)

            # Target is future return of the symbol we're trying to predict
            target = all_returns[symbol].shift(-prediction_horizon)

            # Combine features and target
            model_data = pd.concat([feature_df, target], axis=1)
            model_data.columns = list(feature_df.columns) + ['target']

            # Remove rows with NaN values
            model_data = model_data.dropna()

            if len(model_data) < 30:  # Need sufficient data for reliable prediction
                self.logger.warning(f"Insufficient data for prediction after preprocessing: {len(model_data)} rows")
                return {"error": "Insufficient data for prediction"}

            # Split data into training and testing sets
            train_size = int(len(model_data) * 0.8)
            train_data = model_data.iloc[:train_size]
            test_data = model_data.iloc[train_size:]

            # Train a simple linear regression model
            from sklearn.linear_model import LinearRegression

            # Ensure all data is float type
            X_train = train_data.drop('target', axis=1).astype(float)
            y_train = train_data['target'].astype(float)

            model = LinearRegression()
            model.fit(X_train, y_train)

            # Evaluate on test set - ensure test data is also float type
            X_test = test_data.drop('target', axis=1).astype(float)
            y_test = test_data['target'].astype(float)

            test_score = model.score(X_test, y_test)
            self.logger.info(f"Prediction model R¬≤ score: {test_score:.4f}")

            # Get the most recent data for prediction
            latest_data = feature_df.iloc[-1:].astype(float)
            if latest_data.isnull().values.any():
                latest_data = latest_data.fillna(0)  # Handle any missing values in latest data

            # Make prediction for future movement
            predicted_return = float(model.predict(latest_data)[0])  # Ensure result is float

            # Get feature importances (coefficients)
            feature_importance = dict(zip(X_train.columns, model.coef_))

            # Sort features by absolute importance
            sorted_features = sorted(feature_importance.items(), key=lambda x: abs(x[1]), reverse=True)
            top_features = dict(sorted_features[:5])  # Top 5 most important features

            # Calculate confidence metric based on historical accuracy
            from sklearn.metrics import mean_squared_error
            y_pred_test = model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred_test)
            rmse = np.sqrt(mse)

            # Normalize RMSE to get a confidence score between 0 and 1
            avg_abs_return = np.mean(np.abs(y_test))
            confidence = float(max(0, min(1, 1 - (rmse / (avg_abs_return * 2)))))  # Ensure result is float

            # Get current price for the symbol and ensure it's float
            current_price = float(close_prices[symbol].iloc[-1])

            # Calculate predicted price
            predicted_price = current_price * (1 + predicted_return)

            # Prepare results
            results = {
                "symbol": symbol,
                "current_price": current_price,
                "predicted_return": predicted_return,
                "predicted_price": predicted_price,
                "prediction_horizon": prediction_horizon,
                "prediction_direction": "up" if predicted_return > 0 else "down",
                "confidence": confidence,
                "model_r2": float(test_score),  # Ensure R¬≤ is float
                "top_indicators": {k: float(v) for k, v in top_features.items()},  # Convert coefficients to float
                "prediction_timestamp": datetime.now()
            }

            # Save prediction to database
            prediction_record = {
                "target_symbol": symbol,
                "predicted_return": predicted_return,
                "prediction_horizon": prediction_horizon,
                "confidence": confidence,
                "model_type": "linear_regression",
                "prediction_time": datetime.now(),
                "timeframe": timeframe
                # Additional fields could be added if needed
            }

            # self.db_manager.save_prediction(prediction_record)

            self.logger.info(f"Successfully generated prediction for {symbol} with {prediction_horizon} periods horizon")
            return results

        except Exception as e:
            self.logger.error(f"Error in correlated movement prediction: {str(e)}")
            return {"error": str(e)}


    def analyze_market_regime_correlations(self, symbols: List[str],
                                           market_regimes: Dict[Tuple[datetime, datetime], str],
                                           timeframe: str = None) -> Dict[str, Dict[str, pd.DataFrame]]:
        """
           –ê–Ω–∞–ª—ñ–∑—É—î –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ —Å–∏–º–≤–æ–ª–∞–º–∏ —É –º–µ–∂–∞—Ö –∑–∞–¥–∞–Ω–∏—Ö —Ä–∏–Ω–∫–æ–≤–∏—Ö —Ä–µ–∂–∏–º—ñ–≤.
           –ü—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ–π —Ü—ñ–Ω, –ø—Ä–∏–±—É—Ç–∫—ñ–≤, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ —Ç–∞ –æ–±'—î–º—ñ–≤
           –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–∏–Ω–∫–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º—É –æ–∫—Ä–µ–º–æ.

           Parameters
           ----------
           symbols : List[str]
               –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª—ñ–≤ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç), –¥–ª—è —è–∫–∏—Ö –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –∞–Ω–∞–ª—ñ–∑.
           market_regimes : Dict[Tuple[datetime, datetime], str]
               –°–ª–æ–≤–Ω–∏–∫, –¥–µ –∫–ª—é—á ‚Äî —Ü–µ –ø–∞—Ä–∞ (start_time, end_time), –∞ –∑–Ω–∞—á–µ–Ω–Ω—è ‚Äî –Ω–∞–∑–≤–∞ —Ä–µ–∂–∏–º—É.
           timeframe : str, optional
               –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, '1d', '1h'). –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω–æ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó.

           Returns
           -------
           Dict[str, Dict[str, pd.DataFrame]]
               –°–ª–æ–≤–Ω–∏–∫, —è–∫–∏–π –ø–æ–≤–µ—Ä—Ç–∞—î –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–µ–∂–∏–º—É –≤–∫–ª–∞–¥–µ–Ω—ñ —Å–ª–æ–≤–Ω–∏–∫–∏ –∑ —Ç–∏–ø–∞–º–∏ –∫–æ—Ä–µ–ª—è—Ü—ñ–π:
               regime_name ‚Üí {
                   "price": pd.DataFrame,
                   "returns": pd.DataFrame,
                   "volatility": pd.DataFrame,
                   "volume": pd.DataFrame
               }

           Raises
           ------
           Exception
               –£ —Ä–∞–∑—ñ —Ñ–∞—Ç–∞–ª—å–Ω–æ—ó –ø–æ–º–∏–ª–∫–∏ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ –ø–æ–≤–µ—Ä—Ç–∞—î –≤–∏–∫–ª—é—á–µ–Ω–Ω—è –∑ –ª–æ–≥—É–≤–∞–Ω–Ω—è–º.

           """
        # Use default timeframe from config if not specified
        timeframe = timeframe or self.config['default_timeframe']

        self.logger.info(
            f"Analyzing market regime correlations for {len(symbols)} symbols across {len(market_regimes)} regimes")

        # Dictionary to store results by regime
        regime_correlations = {}

        # Correlation types to calculate
        correlation_types = ['price', 'returns', 'volatility', 'volume']

        try:
            # Process each market regime
            for (regime_start, regime_end), regime_name in market_regimes.items():
                self.logger.info(f"Analyzing regime '{regime_name}' from {regime_start} to {regime_end}")

                # Skip regimes with invalid time ranges
                if regime_start >= regime_end:
                    self.logger.warning(f"Invalid time range for regime {regime_name}: {regime_start} to {regime_end}")
                    continue

                # Initialize regime entry in results dictionary if not exists
                if regime_name not in regime_correlations:
                    regime_correlations[regime_name] = {}

                # Calculate price correlation for this regime
                try:
                    price_corr = self.calculate_price_correlation(
                        symbols=symbols,
                        timeframe=timeframe,
                        start_time=regime_start,
                        end_time=regime_end
                    )
                    regime_correlations[regime_name]['price'] = price_corr
                    self.logger.debug(f"Calculated price correlation for regime {regime_name}")
                except Exception as e:
                    self.logger.warning(f"Error calculating price correlation for regime {regime_name}: {str(e)}")

                # Calculate returns correlation
                try:
                    returns_corr = self.calculate_returns_correlation(
                        symbols=symbols,
                        timeframe=timeframe,
                        start_time=regime_start,
                        end_time=regime_end
                    )
                    regime_correlations[regime_name]['returns'] = returns_corr
                    self.logger.debug(f"Calculated returns correlation for regime {regime_name}")
                except Exception as e:
                    self.logger.warning(f"Error calculating returns correlation for regime {regime_name}: {str(e)}")

                # Calculate volatility correlation
                try:
                    volatility_corr = self.calculate_volatility_correlation(
                        symbols=symbols,
                        timeframe=timeframe,
                        start_time=regime_start,
                        end_time=regime_end
                    )
                    regime_correlations[regime_name]['volatility'] = volatility_corr
                    self.logger.debug(f"Calculated volatility correlation for regime {regime_name}")
                except Exception as e:
                    self.logger.warning(f"Error calculating volatility correlation for regime {regime_name}: {str(e)}")

                # Calculate volume correlation
                try:
                    volume_corr = self.calculate_volume_correlation(
                        symbols=symbols,
                        timeframe=timeframe,
                        start_time=regime_start,
                        end_time=regime_end
                    )
                    regime_correlations[regime_name]['volume'] = volume_corr
                    self.logger.debug(f"Calculated volume correlation for regime {regime_name}")
                except Exception as e:
                    self.logger.warning(f"Error calculating volume correlation for regime {regime_name}: {str(e)}")

                # Calculate average correlations for this regime
                if 'returns' in regime_correlations[regime_name]:
                    returns_matrix = regime_correlations[regime_name]['returns']

                    # Get average correlation value (excluding self-correlations)
                    corr_values = []
                    for i in range(len(symbols)):
                        for j in range(i + 1, len(symbols)):
                            corr_values.append(returns_matrix.iloc[i, j])

                    avg_corr = sum(corr_values) / len(corr_values) if corr_values else 0
                    self.logger.info(f"Regime {regime_name} - Average correlation: {avg_corr:.4f}")

            # Save regime correlation analysis to database
            for regime_name, correlation_data in regime_correlations.items():
                for corr_type, corr_matrix in correlation_data.items():
                    # Create record
                    regime_start, regime_end = None, None
                    for (start, end), name in market_regimes.items():
                        if name == regime_name:
                            regime_start, regime_end = start, end
                            break

                    if regime_start and regime_end:
                        record = {
                            'regime_name': regime_name,
                            'correlation_type': corr_type,
                            'timeframe': timeframe,
                            'start_time': regime_start,
                            'end_time': regime_end,
                            'analysis_time': datetime.now(),
                            'symbols': symbols,
                            'matrix_json': corr_matrix.to_json()
                        }

                        # Assuming we have a method to save regime correlation data
                        if hasattr(self.db_manager, 'save_market_regime_correlation'):
                            self.db_manager.save_market_regime_correlation(record)
                            self.logger.debug(f"Saved {corr_type} correlation for regime {regime_name} to database")

            self.logger.info(f"Market regime correlation analysis complete for {len(regime_correlations)} regimes")
            return regime_correlations

        except Exception as e:
            self.logger.error(f"Error analyzing market regime correlations: {str(e)}")
            raise


def main():
    """
    –¢–µ—Å—Ç–æ–≤–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π –∫–ª–∞—Å—É MarketCorrelation
    """
    print("–ü–æ—á–∞—Ç–æ–∫ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è MarketCorrelation...")

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –æ–±'—î–∫—Ç–∞ –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
    mc = MarketCorrelation()

    # –°–ø–∏—Å–æ–∫ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–∏—Ö –ø–∞—Ä –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    symbols = ['BTC', 'ETH','SOL']
    print(f"–ê–Ω–∞–ª—ñ–∑—É—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω—ñ —Å–∏–º–≤–æ–ª–∏: {', '.join(symbols)}")

    # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è —á–∞—Å–æ–≤–∏—Ö —Ä–∞–º–æ–∫ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    end_time = datetime.now()
    start_time = end_time - timedelta(days=30)  # –¥–∞–Ω—ñ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤
    print(f"–ü–µ—Ä—ñ–æ–¥ –∞–Ω–∞–ª—ñ–∑—É: –∑ {start_time.strftime('%Y-%m-%d')} –ø–æ {end_time.strftime('%Y-%m-%d')}")

    # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–∞–π–º—Ñ—Ä–µ–π–º—É
    timeframe = '1h'  # 1-–≥–æ–¥–∏–Ω–Ω–∏–π —Ç–∞–π–º—Ñ—Ä–µ–π–º

    try:
        # 1. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ü—ñ–Ω
        print("\n1. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ü—ñ–Ω...")
        price_corr = mc.calculate_price_correlation(
            symbols=symbols,
            timeframe=timeframe,
            start_time=start_time,
            end_time=end_time
        )
        print("–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó —Ü—ñ–Ω:")
        print(price_corr.round(2))

        # 2. –ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è –≤–∏—Å–æ–∫–æ –∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω–∏—Ö –ø–∞—Ä –∞–∫—Ç–∏–≤—ñ–≤
        print("\n2. –í–∏—Å–æ–∫–æ –∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ –ø–∞—Ä–∏:")
        correlated_pairs = mc.get_correlated_pairs(price_corr, threshold=0.7)
        for symbol1, symbol2, corr in correlated_pairs:
            print(f"{symbol1} —ñ {symbol2}: {corr:.4f}")

        # 3. –ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è –∞–Ω—Ç–∏-–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω–∏—Ö –ø–∞—Ä –∞–∫—Ç–∏–≤—ñ–≤
        print("\n3. –ê–Ω—Ç–∏-–∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω—ñ –ø–∞—Ä–∏:")
        anticorrelated_pairs = mc.get_anticorrelated_pairs(price_corr, threshold=-0.3)
        for symbol1, symbol2, corr in anticorrelated_pairs:
            print(f"{symbol1} —ñ {symbol2}: {corr:.4f}")

        # 4. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ
        print("\n4. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ...")
        returns_corr = mc.calculate_returns_correlation(
            symbols=symbols,
            timeframe=timeframe,
            start_time=start_time,
            end_time=end_time
        )
        print("–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ:")
        print(returns_corr.round(2))

        # 5. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ
        print("\n5. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ...")
        volatility_corr = mc.calculate_volatility_correlation(
            symbols=symbols,
            timeframe=timeframe,
            start_time=start_time,
            end_time=end_time
        )
        print("–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—ñ:")
        print(volatility_corr.round(2))

        # 6. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–±'—î–º—É —Ç–æ—Ä–≥—ñ–≤–ª—ñ
        print("\n6. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–±'—î–º—É —Ç–æ—Ä–≥—ñ–≤–ª—ñ...")
        volume_corr = mc.calculate_volume_correlation(
            symbols=symbols,
            timeframe=timeframe,
            start_time=start_time,
            end_time=end_time
        )
        print("–ú–∞—Ç—Ä–∏—Ü—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–±'—î–º—É —Ç–æ—Ä–≥—ñ–≤–ª—ñ:")
        print(volume_corr.round(2))

        # 7. –í–∏–±—ñ—Ä –æ–¥–Ω—ñ—î—ó –ø–∞—Ä–∏ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –¥–∏–Ω–∞–º—ñ—á–Ω–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
        if correlated_pairs:
            symbol1, symbol2, _ = correlated_pairs[0]
            print(f"\n7. –ê–Ω–∞–ª—ñ–∑ –¥–∏–Ω–∞–º—ñ—á–Ω–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ {symbol1} —ñ {symbol2}...")

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –∑–º—ñ–Ω–Ω–æ—ó –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –∑ —á–∞—Å–æ–º
            rolling_corr = mc.calculate_rolling_correlation(
                symbol1=symbol1,
                symbol2=symbol2,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                window=24  # –≤—ñ–∫–Ω–æ —É 24 –≥–æ–¥–∏–Ω–∏
            )

            print(f"–ü–æ—Ç–æ—á–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è: {rolling_corr.iloc[-1]:.4f}")

            # –í–∏—è–≤–ª–µ–Ω–Ω—è –∑–ª–∞–º—ñ–≤ —É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
            print("\n8. –í–∏—è–≤–ª–µ–Ω–Ω—è –∑–ª–∞–º—ñ–≤ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó...")
            breakdown_points = mc.detect_correlation_breakdowns(
                symbol1=symbol1,
                symbol2=symbol2,
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time,
                threshold=0.2  # —Å—É—Ç—Ç—î–≤–∞ –∑–º—ñ–Ω–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó
            )

            print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(breakdown_points)} —Ç–æ—á–æ–∫ –∑–ª–∞–º—É –∫–æ—Ä–µ–ª—è—Ü—ñ—ó")
            if breakdown_points:
                for point in breakdown_points:
                    print(f"–ó–ª–∞–º –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –Ω–∞ {point}")

        # 9. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –±–µ—Ç–∏ –≤—ñ–¥–Ω–æ—Å–Ω–æ BTC
        print("\n9. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –±–µ—Ç–∏ –≤—ñ–¥–Ω–æ—Å–Ω–æ BTC...")
        for symbol in symbols:
            if symbol == 'BTC':
                continue

            beta = mc.calculate_market_beta(
                symbol=symbol,
                market_symbol='BTC',
                timeframe=timeframe,
                start_time=start_time,
                end_time=end_time
            )

            if isinstance(beta, float):
                print(f"–ë–µ—Ç–∞ –¥–ª—è {symbol} –≤—ñ–¥–Ω–æ—Å–Ω–æ BTC: {beta:.4f}")

        # 10. –ü–æ—à—É–∫ –≤–µ–¥—É—á–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
        print("\n10. –ü–æ—à—É–∫ –≤–µ–¥—É—á–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –¥–ª—è BTCUSDT...")
        other_symbols = [s for s in symbols if s != 'BTC']
        leading_indicators = mc.find_leading_indicators(
            target_symbol='BTC',
            candidate_symbols=other_symbols,
            lag_periods=[1, 2, 3, 6, 12, 24],  # –ª–∞–≥–∏ —É –≥–æ–¥–∏–Ω–∞—Ö
            timeframe=timeframe,
            start_time=start_time,
            end_time=end_time
        )

        print("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É –≤–µ–¥—É—á–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤:")
        for symbol, lags in leading_indicators.items():
            best_lag = max(lags.items(), key=lambda x: abs(x[1]))
            print(f"{symbol} –Ω–∞ –ª–∞–≥—É {best_lag[0]} –≥–æ–¥–∏–Ω: –∫–æ—Ä–µ–ª—è—Ü—ñ—è {best_lag[1]:.4f}")

        # 11. –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ä—É—Ö—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤
        print("\n11. –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ä—É—Ö—É BTC –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ—Ä–µ–ª—å–æ–≤–∞–Ω–∏—Ö –∞–∫—Ç–∏–≤—ñ–≤...")
        prediction = mc.correlated_movement_prediction(
            symbol='BTC',
            correlated_symbols=other_symbols,
            prediction_horizon=24,  # –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 24 –≥–æ–¥–∏–Ω–∏
            timeframe=timeframe
        )

        print("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è:")
        for key, value in prediction.items():
            print(f"{key}: {value}")

        # 12. –ê–Ω–∞–ª—ñ–∑ –∫–æ—Ä–µ–ª—è—Ü—ñ–π –∑–∞ —Ä—ñ–∑–Ω–∏—Ö —Ä–∏–Ω–∫–æ–≤–∏—Ö —Ä–µ–∂–∏–º—ñ–≤
        print("\n12. –ê–Ω–∞–ª—ñ–∑ –∫–æ—Ä–µ–ª—è—Ü—ñ–π –∑–∞ —Ä—ñ–∑–Ω–∏—Ö —Ä–∏–Ω–∫–æ–≤–∏—Ö —Ä–µ–∂–∏–º—ñ–≤...")
        # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–∏–Ω–∫–æ–≤–∏—Ö —Ä–µ–∂–∏–º—ñ–≤ (–ø—Ä–∏–∫–ª–∞–¥)
        regime_start = start_time
        regime_mid = start_time + (end_time - start_time) / 2

        market_regimes = {
            (regime_start, regime_mid): "–ü–µ—Ä—à–∞ –ø–æ–ª–æ–≤–∏–Ω–∞ –ø–µ—Ä—ñ–æ–¥—É",
            (regime_mid, end_time): "–î—Ä—É–≥–∞ –ø–æ–ª–æ–≤–∏–Ω–∞ –ø–µ—Ä—ñ–æ–¥—É"
        }

        regime_correlations = mc.analyze_market_regime_correlations(
            symbols=symbols,
            market_regimes=market_regimes,
            timeframe=timeframe
        )

        print("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑—É —Ä–∏–Ω–∫–æ–≤–∏—Ö —Ä–µ–∂–∏–º—ñ–≤:")
        for regime_name, corr_data in regime_correlations.items():
            if 'returns' in corr_data:
                returns_matrix = corr_data['returns']
                avg_corr = returns_matrix.values[np.triu_indices_from(returns_matrix.values, k=1)].mean()
                print(f"–†–µ–∂–∏–º '{regime_name}' - —Å–µ—Ä–µ–¥–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—ñ: {avg_corr:.4f}")

        print("\n–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è MarketCorrelation –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")

    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—ñ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

